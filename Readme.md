Remarks:
1. Should be run on linux server. (vllm installation issue)
2. 2 ports are required. The model is served on 8128, fastapi listen to 10928. You can change them in runModel.sh and config.p